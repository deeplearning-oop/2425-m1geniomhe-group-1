{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_dataset import MNIST, viz_ndarray\n",
    "from new_dataloader import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28) 5\n",
      "(1, 28, 28) 0\n",
      "(1, 28, 28) 4\n",
      "(1, 28, 28) 1\n",
      "(1, 28, 28) 9\n",
      "x type: <class 'tensor.Tensor'>, y type: <class 'int'>\n",
      "x shape: (1, 28, 28), y shape: no shape its an int\n",
      "data: Tensor([[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126\n",
      "   136 175  26 166 255 247 127   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253\n",
      "   253 225 172 253 242 195  64   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253\n",
      "   251  93  82  82  56  39   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247\n",
      "   241   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43\n",
      "   154   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108\n",
      "     1   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253\n",
      "   119  25   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253\n",
      "   253 150  27   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93\n",
      "   252 253 187   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   249 253 249  64   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183\n",
      "   253 253 207   2   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253\n",
      "   253 250 182   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253\n",
      "   201  78   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81\n",
      "     2   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]]], requires_grad=False)\n",
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "train_data=MNIST(root='data', train=True, download=True)\n",
    "\n",
    "viz_ndarray(train_data[0][0],label=f'label: {train_data[0][1]}', squeeze=True)\n",
    "for i in range(5):\n",
    "    print(train_data[i][0].shape, train_data[i][1])\n",
    "\n",
    "for x,y in train_data:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n",
      "torch.Size([1, 28, 28]) 0\n",
      "torch.Size([1, 28, 28]) 4\n",
      "torch.Size([1, 28, 28]) 1\n",
      "torch.Size([1, 28, 28]) 9\n",
      "x type: <class 'torch.Tensor'> and dtype: torch.float32, y type: <class 'int'>\n",
      "x shape: torch.Size([1, 28, 28]), y shape: no shape its an int\n",
      "data: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "transforms=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "torch_train_data = datasets.MNIST('data', train=True, download=True, transform=transforms)\n",
    "for i in range(5):\n",
    "    print(torch_train_data[i][0].shape, torch_train_data[i][1])\n",
    "for x,y in torch_train_data:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x type: <class 'tensor.Tensor'>, y type: <class 'tensor.Tensor'>\n",
      "x shape: (32, 1, 28, 28), y shape: (32,)\n",
      "data: Tensor([[[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]], requires_grad=False)\n",
      "label: Tensor([6 9 1 9 1 0 5 5 4 3 6 4 8 6 9 7 1 8 0 0 4 8 8 9 9 3 4 9 4 0 6 7], requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x type: <class 'torch.Tensor'> and dtype: torch.float32, y type: <class 'torch.Tensor'>\n",
      "x shape: torch.Size([32, 1, 28, 28]), y shape: torch.Size([32])\n",
      "data: tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "label: tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "torch_train_loader=torch.utils.data.DataLoader(torch_train_data, batch_size=32)\n",
    "\n",
    "for x,y in torch_train_loader:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(x, y) in enumerate(train_loader):\n",
    "    print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPVElEQVR4nO3caYjVZfvA8euYlZozo0SFQzWmZQUlYRHtWdOGUm+KaEWJygJbKCiIKCgqIiqICEtqMql4DMsWqLB9oRcxVrS4hCktQ5QtM5OWVvN7XvTv4vGf5txHZ1E/H/CF5/yu+d1jMV/vc453raqqKgAgIoYM9AIAGDxEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEgUHn0UcfjVqtFitXriyenTx5chx00EFbdD1jx46N6dOnb9GvCYOVKEAf6ujoiAsuuCD233//aGhoiFGjRsXhhx8ec+bMCSfMMBgNHegFwLZs1apV8fXXX8dZZ50Ve++9d/z++++xcOHCmD59eixdujRuv/32gV4irEcUoA9NnDgx3njjjfUemzlzZpx++ulx3333xa233ho77LDDwCwONsDLR2wVnn322Zg6dWo0NzfHzjvvHOPHj49bb701/vzzzw1e397eHkcddVQMHz489tlnn5g1a9Y/rlm7dm3cfPPNse+++8bOO+8ce+21V1x33XWxdu3aTa5n+fLlsXz58rq/n7Fjx8aaNWti3bp1dX8N6At2CmwVHn300Rg5cmRcc801MXLkyHjttdfipptuiq6urrjrrrvWu/ann36KKVOmxNlnnx3nnntuzJs3Ly6//PLYaaed4qKLLoqIiJ6enjjjjDPinXfeiUsvvTQOPPDA+Pjjj+Pee++NZcuWxYIFC/51Pa2trRERvX4z/Ndff43Vq1fHL7/8Em+++Wa0tbXFkUceGcOHDy/+s4A+VcEg09bWVkVEtWLFinxszZo1/7huxowZ1YgRI6rffvstHzv++OOriKjuvvvufGzt2rXVIYccUu2+++7VunXrqqqqqrlz51ZDhgyp3n777fW+5qxZs6qIqN599918rKWlpZo2bdp617W0tFQtLS29/p7uuOOOKiLyV2tra/Xll1/2eh76i5eP2Cr879+ou7u7Y9WqVXHsscfGmjVrYsmSJetdO3To0JgxY0b+fqeddooZM2bEd999F+3t7RER8dRTT8WBBx4YBxxwQKxatSp/nXjiiRER8frrr//relauXFn0kdlzzz03Fi5cGE888UScd955EfHX7gEGGy8fsVX49NNP48Ybb4zXXnsturq61nuus7Nzvd83NzfHLrvsst5jEyZMiIi/fpgfccQR8fnnn8fixYtjt9122+D9vvvuuy24+oiWlpZoaWmJiL8Ccemll8ZJJ50US5cu9RISg4ooMOj9/PPPcfzxx0djY2PccsstMX78+Bg2bFgsWrQorr/++ujp6Sn+mj09PXHwwQfHPffcs8Hn99prr81d9r8666yzYvbs2fHWW2/Fqaee2qf3ghKiwKD3xhtvxA8//BBPP/10HHfccfn4ihUrNnh9R0dHrF69er3dwrJlyyLir0/9RESMHz8+Pvroo2htbY1ardZ3i9+Iv186+v+7HBho3lNg0Pv7c/zV//wL4HXr1sUDDzywwev/+OOPePDBB9e79sEHH4zddtstDj300IiIOPvss+Obb76J2bNn/2P+708K/ZvefiT1+++/3+DjDz/8cNRqtZg0adImvwb0JzsFBr2jjjoqRo8eHdOmTYsrr7wyarVazJ07d6PHRDQ3N8edd94ZK1eujAkTJsR//vOf+PDDD+Ohhx6KHXfcMSIiLrzwwpg3b15cdtll8frrr8fRRx8df/75ZyxZsiTmzZsXL7/8chx22GEbXVNvP5J62223xbvvvhunnXZa7L333vHjjz/G/Pnz4/33348rrrgi9t133/r+UKCPiAKD3q677hovvPBCXHvttXHjjTfG6NGj44ILLojW1tYNvh4/evTomDNnTlxxxRUxe/bs2GOPPeL++++PSy65JK8ZMmRILFiwIO6999547LHH4plnnokRI0bEuHHj4qqrrso3pjfX1KlTY/ny5fHII4/E999/H8OGDYuJEydGW1tbTJs2bYvcA7akWrWxv24BsN3xngIASRQASKIAQBIFAJIoAJB69ZHUnp6e6OjoiIaGhgH5158AbJ6qqqK7uzuam5tjyJCN7wd6FYWOjo4+PwsGgL731VdfxZ577rnR53v18lFDQ8MWWxAAA2dTP897FQUvGQFsGzb189wbzQAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBo60Atg63TMMccUz7z11lt13eunn34qnnn11VeLZ0aNGlU8s2jRouKZWbNmFc9ERKxcubKuOShhpwBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgFSrqqra1EVdXV3R1NTUH+thK3HhhRcWz8yZM6eue/Xif9EBU6vVime6u7vrulc9Bwqed955xTP1ro+tQ2dnZzQ2Nm70eTsFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkoQO9ALZOn332WfHMe++9V9e99ttvv+KZ4cOHF8+MGDGieKazs7N4ZuTIkcUzERFTpkwpnpk8eXLxzPPPP188w7bDTgGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAKlWVVW1qYu6urqiqampP9YD/9DQ0FA809LSUjwzZsyY4plPPvmkeGbChAnFMxERDz/8cPHMO++8Uzwzffr04hm2Hp2dndHY2LjR5+0UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQhg70AmBTuru7i2fqOaiunpl6/PLLL3XN1Wq1fplh+2anAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJKekwmZoaGgonmlvb6/rXmPHji2eue++++q6F9svOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQH4jHo7bjjjsUzu+66a/FMPQfOPf744/1yn4iIH374oXjmxRdfrOtebL/sFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkByIR79pbm6ua27u3LnFM5MnT67rXqVqtVrxTFVVdd2rra2teGbZsmV13Yvtl50CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSA/HoNyeffHJdcyeccMIWXsnAqucQvYiImTNnFs+88sorxTMLFy4snmHbYacAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkp6TSb0aPHl3X3OrVq4tnPv744+KZ+fPnF8/0p6uvvrp4ZsGCBcUzxx13XPFMe3t78QyDk50CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBSraqqalMXdXV1RVNTU3+sh21YQ0NDXXNjxowpnlm2bFld9xrMzjnnnOKZRx55pHjmo48+Kp456aSTimfqOeiQzdfZ2RmNjY0bfd5OAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyYF4sA176aWXimdOOeWU4pnzzz+/eObJJ58snmHzORAPgF4TBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGANHSgFwD0naeffrp4pp4D8Zqbm4tnGJzsFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkByIB9uwhx56qHhm1qxZxTOjRo0qnmFwslMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBSraqqalMXdXV1RVNTU3+sBxhgzz33XPHMnnvuWTwzadKk4hk2X2dnZzQ2Nm70eTsFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkoQO9gK3N8OHDi2fqOfirVqsVz0REtLe3F8/8+uuvdd2LbdOhhx5aPPPEE0/0wUoYCHYKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABI2/WBeOPGjSue+eCDD4pnGhoaimcGu1deeaV45ttvv63rXlVVFc8sXry4eGbRokXFMx0dHcUzzc3NxTP1uvjii4tn6llfvf9tGXzsFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkLbrA/G++OKL4pmpU6cWz9xwww3FM6eddlrxTER9h8fVo7W1tXimVqvVda/++p7q8dtvvxXPDBs2rA9WsuXU8+f9448/9sFKGAh2CgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASLWqF6dfdXV1RVNTU3+sh/8zceLEuuYmTZpUPHPmmWcWzxx99NHFM6NGjSqeiRjcB+LVc8hff34/a9asKZ5pa2srnrnmmmuKZ/7444/iGTZfZ2dnNDY2bvR5OwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACA5JZW6jBkzpnjmoIMOqute9ZziOmzYsOKZcePGFc8cc8wxxTPz5s0rnomImD9/fvHM4sWLi2c++eST4hm2Hk5JBaDXRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIDkQD2A74kA8AHpNFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACD1KgpVVfX1OgDoB5v6ed6rKHR3d2+RxQAwsDb187xW9WIb0NPTEx0dHdHQ0BC1Wm2LLQ6A/lFVVXR3d0dzc3MMGbLx/UCvogDA9sEbzQAkUQAgiQIASRQASKIAQBIFAJIoAJD+C9xbyqu7ZOcuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], requires_grad=False, grad_fn=<DivBackward>) float64 (784, 32)\n",
      "iteration: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# if _ % 100 == 0:\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)    \n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m    109\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_hat\u001b[38;5;241m.\u001b[39mdata, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    110\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(predictions \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m/\u001b[39m y\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from module import Module\n",
    "from linear import Linear\n",
    "from optimizer import SGD\n",
    "from loss import CrossEntropyLoss, MSE\n",
    "# from dataset import MNIST\n",
    "# from dataloader import DataLoader\n",
    "# from transformer import get_transform\n",
    "from tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "from new_dataset import MNIST, viz_ndarray\n",
    "from new_dataloader import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('../tests/data/MNIST.csv')\n",
    "\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255\n",
    "_,m_train = X_train.shape\n",
    "\n",
    "# print('X dev shape:', X_dev.shape)\n",
    "# print('Y dev shape:', Y_dev.shape)\n",
    "\n",
    "# print('X train shape:', X_train.shape)\n",
    "# print('Y train shape:', Y_train.shape)\n",
    "\n",
    "# for _ in range(501):\n",
    "#     x=Tensor(X_train, requires_grad=False)\n",
    "#     y=Tensor(Y_train, requires_grad=False)\n",
    "#     print(x,x.shape)\n",
    "#     print(y,y.shape)\n",
    "#     break\n",
    "\n",
    "train_data = MNIST(root='data/', train=True, download=True)\n",
    "test_data = MNIST(root='data/', train=False, download=True)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# for i,(x, y) in enumerate(train_loader):\n",
    "#     print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "#     if i==5:\n",
    "#         break\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "##########################################\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(20, 28*28)\n",
    "        self.linear2 = Linear(10, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear2(x)\n",
    "        return x.softmax()\n",
    "    \n",
    "model = Model()\n",
    "optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "for _ in range(5):\n",
    "    # x=Tensor(X_train, requires_grad=False)\n",
    "    # y=Tensor(Y_train, requires_grad=False)\n",
    "    for x_wannabe,y_wannabe in train_loader:\n",
    "        x_wannabe=x_wannabe/255\n",
    "        viz_ndarray(x_wannabe[1], squeeze=True, label=f'label: {y_wannabe[1]}')\n",
    "        x_wannabe.flatten_batch()\n",
    "        \n",
    "        # print(x_wannabe,x_wannabe.data.dtype,x_wannabe.shape)\n",
    "        x=x_wannabe\n",
    "        y=y_wannabe\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y, y_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # break\n",
    "    # if _ % 100 == 0:\n",
    "    print(f'iteration: {_}')    \n",
    "    print(f'Loss: {loss.data}') \n",
    "    predictions = np.argmax(y_hat.data, axis=0)\n",
    "    accuracy = np.sum(predictions == y.data) / y.data.size\n",
    "    print(predictions, y.data)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
