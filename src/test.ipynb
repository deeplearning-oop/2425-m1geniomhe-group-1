{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_dataset import MNIST, viz_ndarray\n",
    "from new_dataloader import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28) 5\n",
      "(1, 28, 28) 0\n",
      "(1, 28, 28) 4\n",
      "(1, 28, 28) 1\n",
      "(1, 28, 28) 9\n",
      "x type: <class 'tensor.Tensor'>, y type: <class 'int'>\n",
      "x shape: (1, 28, 28), y shape: no shape its an int\n",
      "data: Tensor([[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126\n",
      "   136 175  26 166 255 247 127   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253\n",
      "   253 225 172 253 242 195  64   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253\n",
      "   251  93  82  82  56  39   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247\n",
      "   241   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43\n",
      "   154   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108\n",
      "     1   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253\n",
      "   119  25   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253\n",
      "   253 150  27   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93\n",
      "   252 253 187   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   249 253 249  64   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183\n",
      "   253 253 207   2   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253\n",
      "   253 250 182   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253\n",
      "   201  78   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81\n",
      "     2   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]]], requires_grad=False)\n",
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "train_data=MNIST(root='data', train=True, download=True)\n",
    "\n",
    "viz_ndarray(train_data[0][0],label=f'label: {train_data[0][1]}', squeeze=True)\n",
    "for i in range(5):\n",
    "    print(train_data[i][0].shape, train_data[i][1])\n",
    "\n",
    "for x,y in train_data:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n",
      "torch.Size([1, 28, 28]) 0\n",
      "torch.Size([1, 28, 28]) 4\n",
      "torch.Size([1, 28, 28]) 1\n",
      "torch.Size([1, 28, 28]) 9\n",
      "x type: <class 'torch.Tensor'> and dtype: torch.float32, y type: <class 'int'>\n",
      "x shape: torch.Size([1, 28, 28]), y shape: no shape its an int\n",
      "data: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "transforms=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "torch_train_data = datasets.MNIST('data', train=True, download=True, transform=transforms)\n",
    "for i in range(5):\n",
    "    print(torch_train_data[i][0].shape, torch_train_data[i][1])\n",
    "for x,y in torch_train_data:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x type: <class 'tensor.Tensor'>, y type: <class 'tensor.Tensor'>\n",
      "x shape: (32, 1, 28, 28), y shape: (32,)\n",
      "data: Tensor([[[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   ...\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]\n",
      "   [0 0 0 ... 0 0 0]]]], requires_grad=False)\n",
      "label: Tensor([6 9 1 9 1 0 5 5 4 3 6 4 8 6 9 7 1 8 0 0 4 8 8 9 9 3 4 9 4 0 6 7], requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x type: <class 'torch.Tensor'> and dtype: torch.float32, y type: <class 'torch.Tensor'>\n",
      "x shape: torch.Size([32, 1, 28, 28]), y shape: torch.Size([32])\n",
      "data: tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "label: tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "torch_train_loader=torch.utils.data.DataLoader(torch_train_data, batch_size=32)\n",
    "\n",
    "for x,y in torch_train_loader:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(x, y) in enumerate(train_loader):\n",
    "    print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], requires_grad=False) uint8 (784, 32)\n",
      "iteration: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# if _ % 100 == 0:\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)    \n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m    108\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_hat\u001b[38;5;241m.\u001b[39mdata, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    109\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(predictions \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m/\u001b[39m y\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from module import Module\n",
    "from linear import Linear\n",
    "from optimizer import SGD\n",
    "from loss import CrossEntropyLoss, MSE\n",
    "# from dataset import MNIST\n",
    "# from dataloader import DataLoader\n",
    "# from transformer import get_transform\n",
    "from tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "from new_dataset import MNIST, viz_ndarray\n",
    "from new_dataloader import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('../tests/data/MNIST.csv')\n",
    "\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255\n",
    "_,m_train = X_train.shape\n",
    "\n",
    "# print('X dev shape:', X_dev.shape)\n",
    "# print('Y dev shape:', Y_dev.shape)\n",
    "\n",
    "# print('X train shape:', X_train.shape)\n",
    "# print('Y train shape:', Y_train.shape)\n",
    "\n",
    "# for _ in range(501):\n",
    "#     x=Tensor(X_train, requires_grad=False)\n",
    "#     y=Tensor(Y_train, requires_grad=False)\n",
    "#     print(x,x.shape)\n",
    "#     print(y,y.shape)\n",
    "#     break\n",
    "\n",
    "train_data = MNIST(root='data/', train=True, download=True)\n",
    "test_data = MNIST(root='data/', train=False, download=True)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# for i,(x, y) in enumerate(train_loader):\n",
    "#     print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "#     if i==5:\n",
    "#         break\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "##########################################\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(20, 28*28)\n",
    "        self.linear2 = Linear(10, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear2(x)\n",
    "        return x.softmax()\n",
    "    \n",
    "model = Model()\n",
    "optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "for _ in range(5):\n",
    "    # x=Tensor(X_train, requires_grad=False)\n",
    "    # y=Tensor(Y_train, requires_grad=False)\n",
    "    for x_wannabe,y_wannabe in train_loader:\n",
    "        viz_ndarray(x_wannabe[1], squeeze=True, label=f'label: {y_wannabe[1]}')\n",
    "        x_wannabe.flatten_batch()\n",
    "        \n",
    "        print(x_wannabe,x_wannabe.data.dtype,x_wannabe.shape)\n",
    "        break\n",
    "        x=x_wannabe\n",
    "        y=y_wannabe\n",
    "        # print('hi')\n",
    "        # break\n",
    "        # print(f'x shape: {x.shape}  |  y shape: {y.shape}, type y: {type(y)}')\n",
    "        # print(f'x_wannabe shape: {x_wannabe.shape}  |  y_wannabe shape: {y_wannabe.shape}, type y_wannabe: {type(y_wannabe)}')\n",
    "        # # print(y.data.shape)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y, y_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # break\n",
    "    # if _ % 100 == 0:\n",
    "    print(f'iteration: {_}')    \n",
    "    print(f'Loss: {loss.data}') \n",
    "    predictions = np.argmax(y_hat.data, axis=0)\n",
    "    accuracy = np.sum(predictions == y.data) / y.data.size\n",
    "    print(predictions, y.data)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
