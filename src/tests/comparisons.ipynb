{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Comparisons\n"
      ],
      "metadata": {
        "id": "cegtanFK8ND8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tD65xgvw76YG",
        "outputId": "00aac860-3870-40c0-9c4d-d92c049bd8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/my-stuff/projects/neural network from scratch/src'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/my-stuff/projects/neural network from scratch/src')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from functools import wraps\n",
        "import time\n",
        "\n",
        "class ExecutionTimer:\n",
        "    def __init__(self) -> None:\n",
        "        self.execution_times = {}\n",
        "\n",
        "    def __call__(self, fn):\n",
        "        \"\"\"\n",
        "        Allows the class to be used as a decorator.\n",
        "        \"\"\"\n",
        "        @wraps(fn)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = datetime.datetime.now()\n",
        "            result = fn(*args, **kwargs)\n",
        "            end = datetime.datetime.now()\n",
        "            execution_time = (end - start).total_seconds()\n",
        "            self.execution_times[fn.__name__] = execution_time\n",
        "            print(f\"{fn.__name__} execution time: {execution_time:.2f} seconds\")\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "timer= ExecutionTimer()\n"
      ],
      "metadata": {
        "id": "thKua29L_Zma"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our library"
      ],
      "metadata": {
        "id": "LtejUMRs8LPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "USPMLMLU76YL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from termcolor import colored\n",
        "\n",
        "from module import Module\n",
        "from linear import Linear\n",
        "from optimizer import SGD\n",
        "from loss import CrossEntropyLoss, MSE\n",
        "from activation import ReLU, Softmax\n",
        "from dataset import MNIST\n",
        "from dataloader import DataLoader\n",
        "from transforms import Compose, ToTensor, Normalize, Standardize\n",
        "from tensor import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FUjv10f76YM",
        "outputId": "4fc03d6d-cafb-468a-ac88-7b7242a43bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
            " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
            " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
            " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
            ">>> applying ToTensor()...\n",
            " :O already a tensor\n",
            ">>> applying Standardize(inplace=True)...\n",
            ">>> [ToTensor(), Standardize(inplace=True)] applied successfully <<<\n",
            " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
            " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
            " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
            " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
            " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
            ">>> applying ToTensor()...\n",
            " :O already a tensor\n",
            ">>> applying Standardize(inplace=True)...\n",
            ">>> [ToTensor(), Standardize(inplace=True)] applied successfully <<<\n"
          ]
        }
      ],
      "source": [
        "# -- using our implemented dataset module\n",
        "transformation=Compose([ToTensor(), Standardize()])\n",
        "train_data = MNIST(root='data/', train=True, download=True,transform=transformation)\n",
        "test_data = MNIST(root='data/', train=False, download=True,transform=transformation)\n",
        "\n",
        "# -- using our implemented dataloader module\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3CTH_a_D76YO"
      },
      "outputs": [],
      "source": [
        "# timer()\n",
        "# def train_network_our_library():\n",
        "#     # -- model definition\n",
        "#     class Model(Module):\n",
        "#         def __init__(self):\n",
        "#             super().__init__()\n",
        "#             self.linear1 = Linear(28*28,20)\n",
        "#             self.relu=ReLU()\n",
        "#             self.linear2 = Linear(20, 10)\n",
        "#             self.softmax=Softmax()\n",
        "\n",
        "#         def forward(self, x):\n",
        "#             x = self.linear1(x)\n",
        "#             x = self.relu(x)\n",
        "#             x = self.linear2(x)\n",
        "#             return self.softmax(x)\n",
        "\n",
        "#     model = Model()\n",
        "#     optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#     loss_fn = CrossEntropyLoss()\n",
        "\n",
        "#     accuracies = []\n",
        "\n",
        "#     # -- running the experiment 10 times\n",
        "#     for run in range(10):\n",
        "#         print(f\"Run {run + 1} / 10:\")\n",
        "\n",
        "#         # -- training loop\n",
        "#         for epoch in range(1):  # You can adjust the number of epochs as needed\n",
        "#             for batch_no, (x, y) in enumerate(train_loader):\n",
        "#                 # -> flatten the batch (32, 1, 28, 28) to (784, 32)\n",
        "#                 x = x.flatten_batch()  # (784, 32)\n",
        "\n",
        "#                 optimizer.zero_grad()\n",
        "#                 y_hat = model(x)\n",
        "#                 loss = loss_fn(y, y_hat)\n",
        "#                 loss.backward()\n",
        "#                 optimizer.step()\n",
        "#         # -- testing\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "\n",
        "#         for batch_no, (x, y) in enumerate(test_loader):\n",
        "#             x = x.flatten_batch()\n",
        "#             y_hat = model(x)\n",
        "#             predictions = np.argmax(y_hat, axis=0)\n",
        "#             correct += np.sum(predictions == y)\n",
        "#             total += y.data.size\n",
        "\n",
        "#         accuracy = correct / total * 100\n",
        "#         accuracies.append(accuracy)\n",
        "\n",
        "#         print(f'Accuracy for run {run + 1}: {accuracy:.2f}%')\n",
        "#         print('------------------')\n",
        "#         return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qGYinAyF76YP"
      },
      "outputs": [],
      "source": [
        "@timer\n",
        "def train_network_our_library():\n",
        "\n",
        "    # -- model definition\n",
        "    class Model(Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.linear1 = Linear(28*28,20)\n",
        "            self.relu=ReLU()\n",
        "            self.linear2 = Linear(20, 10)\n",
        "            self.softmax=Softmax()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.linear1(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.linear2(x)\n",
        "            return self.softmax(x)\n",
        "\n",
        "    model = Model()\n",
        "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    train_accuracies = []; epoch_train_accuracies=[]\n",
        "    test_accuracies = [];\n",
        "\n",
        "    # -- running the experiment 10 times\n",
        "    for run in range(10):\n",
        "        print(colored(f\"{'='*10} Run {run + 1} / 10 {'='*10}\", 'cyan', attrs=['bold']))\n",
        "\n",
        "        # -- training loop\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for epoch in range(10):\n",
        "            for batch_no, (x, y) in enumerate(train_loader):\n",
        "                # -> flatten the batch (32, 1, 28, 28) to (784, 32)\n",
        "                x = x.flatten_batch()  # (784, 32)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                y_hat = model(x)\n",
        "                loss = loss_fn(y, y_hat)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "                predictions = np.argmax(y_hat, axis=0)\n",
        "                correct_train += np.sum(predictions == y)\n",
        "                total_train += y.data.size\n",
        "\n",
        "                epoch_train_accuracy = correct_train / total_train * 100\n",
        "                epoch_train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "        train_accuracy = correct_train / total_train * 100\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        print(colored(f\"ğŸ¯ Training Accuracy: {train_accuracy:.2f}%\", 'green'))\n",
        "\n",
        "        # -- testing loop\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        for batch_no, (x, y) in enumerate(test_loader):\n",
        "            x = x.flatten_batch()\n",
        "            y_hat = model(x)\n",
        "            predictions = np.argmax(y_hat, axis=0)\n",
        "            correct_test += np.sum(predictions == y)\n",
        "            total_test += y.data.size\n",
        "\n",
        "        test_accuracy = correct_test / total_test * 100\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        print(colored(f\"ğŸ” Testing Accuracy: {test_accuracy:.2f}%\", 'yellow'))\n",
        "        print(colored('-'*30, 'magenta'))\n",
        "\n",
        "    print(colored(f\"\\n{'='*15} Summary of Results {'='*15}\", 'blue', attrs=['bold']))\n",
        "    for i in range(10):\n",
        "        print(colored(f\"Run {i + 1} - ğŸ‹ï¸ Training: {train_accuracies[i]:.2f}% | ğŸ§ª Testing: {test_accuracies[i]:.2f}%\", 'white'))\n",
        "    print(colored(f\"{'='*50}\", 'blue', attrs=['bold']))\n",
        "    return train_accuracies, epoch_train_accuracies, test_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf78gRah76YQ",
        "outputId": "31ee391e-fcb5-4181-a35f-f8dc3b5fc21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Run 1 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 93.11%\n",
            "ğŸ” Testing Accuracy: 94.58%\n",
            "------------------------------\n",
            "========== Run 2 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 96.04%\n",
            "ğŸ” Testing Accuracy: 94.59%\n",
            "------------------------------\n",
            "========== Run 3 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 96.75%\n",
            "ğŸ” Testing Accuracy: 94.86%\n",
            "------------------------------\n",
            "========== Run 4 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 97.15%\n",
            "ğŸ” Testing Accuracy: 95.24%\n",
            "------------------------------\n",
            "========== Run 5 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 97.39%\n",
            "ğŸ” Testing Accuracy: 95.01%\n",
            "------------------------------\n",
            "========== Run 6 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 97.61%\n",
            "ğŸ” Testing Accuracy: 94.89%\n",
            "------------------------------\n",
            "========== Run 7 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 97.79%\n",
            "ğŸ” Testing Accuracy: 95.01%\n",
            "------------------------------\n",
            "========== Run 8 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 97.94%\n",
            "ğŸ” Testing Accuracy: 94.52%\n",
            "------------------------------\n",
            "========== Run 9 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 98.05%\n",
            "ğŸ” Testing Accuracy: 94.92%\n",
            "------------------------------\n",
            "========== Run 10 / 10 ==========\n",
            "ğŸ¯ Training Accuracy: 98.16%\n",
            "ğŸ” Testing Accuracy: 94.99%\n",
            "------------------------------\n",
            "\n",
            "=============== Summary of Results ===============\n",
            "Run 1 - ğŸ‹ï¸ Training: 93.11% | ğŸ§ª Testing: 94.58%\n",
            "Run 2 - ğŸ‹ï¸ Training: 96.04% | ğŸ§ª Testing: 94.59%\n",
            "Run 3 - ğŸ‹ï¸ Training: 96.75% | ğŸ§ª Testing: 94.86%\n",
            "Run 4 - ğŸ‹ï¸ Training: 97.15% | ğŸ§ª Testing: 95.24%\n",
            "Run 5 - ğŸ‹ï¸ Training: 97.39% | ğŸ§ª Testing: 95.01%\n",
            "Run 6 - ğŸ‹ï¸ Training: 97.61% | ğŸ§ª Testing: 94.89%\n",
            "Run 7 - ğŸ‹ï¸ Training: 97.79% | ğŸ§ª Testing: 95.01%\n",
            "Run 8 - ğŸ‹ï¸ Training: 97.94% | ğŸ§ª Testing: 94.52%\n",
            "Run 9 - ğŸ‹ï¸ Training: 98.05% | ğŸ§ª Testing: 94.92%\n",
            "Run 10 - ğŸ‹ï¸ Training: 98.16% | ğŸ§ª Testing: 94.99%\n",
            "==================================================\n",
            "train_network_our_library execution time: 310.26 seconds\n"
          ]
        }
      ],
      "source": [
        "train_acc, epoch_train_acc, test_acc = train_network_our_library()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_train_accuracy_epochs = sum(epoch_train_acc) / len(epoch_train_acc)\n",
        "print(f'Average Train Accuracy over 10 runs 10 epochs each: {average_train_accuracy_epochs:.2f}%')\n",
        "\n",
        "average_test_accuracy = sum(test_acc) / len(test_acc)\n",
        "print(f'Average Test Accuracy over 10 runs: {average_test_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7a2AfRRCXO4",
        "outputId": "7ee76950-6e37-4af2-a270-6fa5e7b32ba4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Train Accuracy over 10 runs 10 epochs each: 96.55%\n",
            "Average Test Accuracy over 10 runs: 94.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX35nvPQ76YQ"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = datasets.MNIST('data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testset = datasets.MNIST('data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "NeRzcvMmBSDI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @timer\n",
        "# def train_network_pytorch():\n",
        "\n",
        "#     model = nn.Sequential(nn.Linear(28*28, 20), nn.ReLU(), nn.Linear(20, 10), nn.Softmax(dim=1))\n",
        "#     optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#     loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#     train_accuracies = []  # To store training accuracies\n",
        "#     test_accuracies = []   # To store testing accuracies\n",
        "#     epochs_list = []       # To store number of epochs used in each run\n",
        "\n",
        "#     # Run the experiment 10 times\n",
        "#     for run in range(10):\n",
        "#         print(f\"Run {run + 1} / 10:\")\n",
        "\n",
        "#         # Initialize variables for this run\n",
        "#         epoch_accuracies_train = []  # List to store per-epoch training accuracy\n",
        "\n",
        "#         # -- training loop\n",
        "#         model.train()  # Set the model to training mode\n",
        "#         running_loss = 0.0\n",
        "#         correct_train = 0\n",
        "#         total_train = 0\n",
        "\n",
        "#         for epoch in range(10):  # You can adjust the number of epochs as needed\n",
        "#             # epoch_accuracies_train = []\n",
        "\n",
        "#             for batch_no, (x, y) in enumerate(trainloader):\n",
        "#                 x = x.view(x.shape[0], -1)\n",
        "#                 optimizer.zero_grad()\n",
        "#                 y_hat = model(x)\n",
        "#                 loss = loss_fn(y_hat, y)\n",
        "#                 loss.backward()\n",
        "#                 optimizer.step()\n",
        "\n",
        "#                 running_loss += loss.item()  # Keep track of the loss for training\n",
        "#                 predictions = torch.argmax(y_hat, dim=1)\n",
        "#                 correct_train += torch.sum(predictions == y)\n",
        "#                 total_train += y.size(0)\n",
        "\n",
        "#             # Calculate and store the training accuracy for this epoch\n",
        "#             train_accuracy = correct_train / total_train * 100\n",
        "#             epoch_accuracies_train.append(train_accuracy)\n",
        "\n",
        "#         # Store the final training accuracy for this run\n",
        "#         train_accuracies.append(epoch_accuracies_train[-1])\n",
        "#         epochs_list.append(1)  # You can adjust the number of epochs as needed\n",
        "#         print(f'Epoch {epoch + 1}, Training Loss: {running_loss / len(trainloader):.4f}')\n",
        "#         print(f'Training Accuracy for run {run + 1}: {train_accuracies[-1]:.2f}%')\n",
        "\n",
        "#         # -- testing loop\n",
        "#         model.eval()  # Set the model to evaluation mode\n",
        "#         correct_test = 0\n",
        "#         total_test = 0\n",
        "\n",
        "#         with torch.no_grad():  # Disable gradient calculation during testing\n",
        "#             for batch_no, (x, y) in enumerate(testloader):\n",
        "#                 x = x.view(x.shape[0], -1)\n",
        "#                 y_hat = model(x)\n",
        "#                 predictions = torch.argmax(y_hat, dim=1)\n",
        "#                 correct_test += torch.sum(predictions == y)\n",
        "#                 total_test += y.size(0)\n",
        "\n",
        "#         # Calculate and store the testing accuracy\n",
        "#         test_accuracy = correct_test / total_test * 100\n",
        "#         test_accuracies.append(test_accuracy)\n",
        "\n",
        "#         print(f'Pytorch Accuracy for run {run + 1} (Testing): {test_accuracy:.2f}%')\n",
        "#         print('------------------')\n",
        "#         return train_accuracies, epochs_list, test_accuracies"
      ],
      "metadata": {
        "id": "DsRPtwofBPHj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_train_acc, torch_epoch_train_acc, torch_test_acc = train_network_pytorch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwtxpiVAC9OM",
        "outputId": "9ecddeb4-7073-4294-bab2-2e5ac5922886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 / 10:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(colored(f\"\\n{'='*15} Summary of Results {'='*15}\", 'blue', attrs=['bold']))\n",
        "for i in range(10):\n",
        "    print(colored(f\"Run {i + 1} - ğŸ‹ï¸ Training: {torch_train_acc[i]:.2f}% | ğŸ§ª Testing: {torch_test_acc[i]:.2f}%\", 'white'))\n",
        "    print(colored(f\"{'='*50}\", 'blue', attrs=['bold']))\n"
      ],
      "metadata": {
        "id": "ZrXNF7xmFGYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Average Training Accuracy across all runs: {sum(train_accuracies) / len(train_accuracies):.2f}%\")\n",
        "# print(f\"Average Testing Accuracy across all runs: {sum(test_accuracies) / len(test_accuracies):.2f}%\")\n",
        "# print(f\"Epochs used in each run: {epochs_list}\")"
      ],
      "metadata": {
        "id": "RKyuieXSIEih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_C0MPTP76YT",
        "outputId": "a31ad340-5f1f-4756-a574-e24645889be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch Average Train Accuracy over 10 runs 10 epochs each: 96.79%\n",
            "torch Average Test Accuracy over 10 runs: 95.19%\n"
          ]
        }
      ],
      "source": [
        "# torch_average_train_accuracy_epochs = sum(torch_epoch_train_acc) / len(torch_epoch_train_acc)\n",
        "# print(f'torch Average Train Accuracy over 10 runs 10 epochs each: {torch_average_train_accuracy_epochs:.2f}%')\n",
        "\n",
        "torch_average_train_accuracy = sum(torch_train_acc) / len(torch_train_acc)\n",
        "print(f'torch Average Train Accuracy over 10 runs: {torch_average_train_accuracy:.2f}%')\n",
        "\n",
        "torch_average_test_accuracy = sum(torch_test_acc) / len(torch_test_acc)\n",
        "print(f'torch Average Test Accuracy over 10 runs: {torch_average_test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup the figure for plotting\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot 1: torch_test_acc vs test_acc\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, plot 1\n",
        "plt.plot(torch_test_acc, label='Torch Test Accuracy', color='green', linestyle='-', marker='o', markersize=5)\n",
        "plt.plot(test_acc, label='Other Test Accuracy', color='orange', linestyle='--', marker='x', markersize=5)\n",
        "plt.title('Test Accuracy Comparison', fontsize=14)\n",
        "plt.xlabel('Runs (10 runs)', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: torch_train_acc vs train_acc\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, plot 2\n",
        "plt.plot(torch_train_acc, label='Torch Train Accuracy', color='red', linestyle='-', marker='o', markersize=5)\n",
        "plt.plot(train_acc, label='Other Train Accuracy', color='blue', linestyle='--', marker='x', markersize=5)\n",
        "plt.title('Train Accuracy Comparison', fontsize=14)\n",
        "plt.xlabel('Runs (10 runs)', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CUYpikjIIH4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmToVayK76YU"
      },
      "source": [
        "## Comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClEXOW-276YU",
        "outputId": "715a8bd2-838f-4fcd-de5e-308ac1ec26cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_network_our_library': 312.861837}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "timer.execution_times"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}