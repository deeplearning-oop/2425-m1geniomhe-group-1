{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../src')\n",
    "\n",
    "from dataset import MNIST, viz_ndarray\n",
    "from dataloader import DataLoader\n",
    "from transforms import *\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
      " :O already a tensor\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- these are examples of training 5 data points (shape of tensor and label):\n",
      "(1, 28, 28) 5\n",
      "(1, 28, 28) 0\n",
      "(1, 28, 28) 4\n",
      "(1, 28, 28) 1\n",
      "(1, 28, 28) 9\n",
      "x type: <class 'tensor.Tensor'> and dtype: float64, y type: <class 'int'>\n",
      "x shape: (1, 28, 28), y shape: no shape its an int\n"
     ]
    }
   ],
   "source": [
    "train_data=MNIST(root='data', train=True, download=True,transform=ToTensor())\n",
    "\n",
    "viz_ndarray(train_data[0][0],label=f'label: {train_data[0][1]}', squeeze=True)\n",
    "print('-- these are examples of training 5 data points (shape of tensor and label):')\n",
    "for i in range(5):\n",
    "    print(train_data[i][0].shape, train_data[i][1])\n",
    "\n",
    "for x,y in train_data:\n",
    "    print(f'x type: {type(x)} and dtype: {x.data.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- these are examples of training 5 data points (shape of tensor and label):\n",
      "torch.Size([1, 28, 28]) 5\n",
      "torch.Size([1, 28, 28]) 0\n",
      "torch.Size([1, 28, 28]) 4\n",
      "torch.Size([1, 28, 28]) 1\n",
      "torch.Size([1, 28, 28]) 9\n",
      "x type: <class 'torch.Tensor'> and dtype: torch.float32, y type: <class 'int'>\n",
      "x shape: torch.Size([1, 28, 28]), y shape: no shape its an int\n"
     ]
    }
   ],
   "source": [
    "torch_train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print('-- these are examples of training 5 data points (shape of tensor and label):')\n",
    "for i in range(5):\n",
    "    print(torch_train_data[i][0].shape, torch_train_data[i][1])\n",
    "for x,y in torch_train_data:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> File downloaded successfully as 'data/MNIST/raw/train-labels-idx1-ubyte.gz'.\n",
      " >>> File downloaded successfully as 'data/MNIST/raw/t10k-labels-idx1-ubyte.gz'.\n",
      " >>> File downloaded successfully as 'data/MNIST/raw/t10k-images-idx3-ubyte.gz'.\n",
      " >>> File downloaded successfully as 'data/MNIST/raw/train-images-idx3-ubyte.gz'.\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# validation that MNIST is the same\n",
    "\n",
    "# validation\n",
    "\n",
    "my_train_data=MNIST(root='data',train=True) #Dataset\n",
    "my_train_tensor=my_train_data.data #Tensor\n",
    "my_train_ndarray=my_train_tensor.data #ndarray\n",
    "my_train_in_torch_tensor=torch.tensor(my_train_ndarray) #torch.tensor\n",
    "\n",
    "torch_train_data=datasets.MNIST(root='data',train=True,download=True) #torchvision.datasets.MNIST\n",
    "torch_train_tensor=torch_train_data.data #torch.Tensor\n",
    "# print(type(torch_train_data.data)) # <class 'torch.Tensor'>\n",
    "\n",
    "print(torch.all(my_train_in_torch_tensor==torch_train_tensor))\n",
    "# tensor(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
      "before transform: min: 0, max: 255\n",
      " :O already a tensor\n",
      "after transform: min: 0.0, max: 1.0\n"
     ]
    }
   ],
   "source": [
    "transformation=ToTensor()\n",
    "train_data=MNIST(root='data', train=True, download=True)\n",
    "\n",
    "x=train_data[0][0]\n",
    "print(f'before transform: min: {np.min(x.data)}, max: {np.max(x.data)}')\n",
    "transformation(x) #performs transformation inplace, now x is modified\n",
    "print(f'after transform: min: {np.min(x.data)}, max: {np.max(x.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now putting it into use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
      " :O already a tensor\n",
      "with toTensor, min: 0.0, max: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_data_toTensor=MNIST(root='data', train=True, download=True, transform=ToTensor())\n",
    "x=train_data_toTensor[0][0]\n",
    "print(f'with toTensor, min: {np.min(x.data)}, max: {np.max(x.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
      "\n",
      "before transform: Tensor([1 2 3 4 5], requires_grad=False)\n",
      "\t mean: 3.0, std: 1.4142135623730951\n",
      "after transform: Tensor([-1.41421356 -0.70710678  0.          0.70710678  1.41421356], requires_grad=False)\n",
      "\t mean: 0.0, std: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# -- the default behavior=> standardizes tensor so should have mean 0 and std 1 is works\n",
    "transformation=Normalize(inplace=True) \n",
    "train_data=MNIST(root='data', train=True, download=True)\n",
    "\n",
    "x=Tensor([1,2,3,4,5])\n",
    "print(f'\\nbefore transform: {x}\\n\\t mean: {np.mean(x.data)}, std: {np.std(x.data)}')\n",
    "transformation(x) #performs transformation inplace, now x is modified\n",
    "print(f'after transform: {x}\\n\\t mean: {np.mean(x.data)}, std: {np.std(x.data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
      "with Normalize, mean: 0.022782921000724925, std: 1.0137631855674378\n"
     ]
    }
   ],
   "source": [
    "train_data_Normalize=MNIST(root='data', train=True, download=True, transform=Normalize())\n",
    "x=train_data_Normalize[0][0]\n",
    "print(f'with Normalize, mean: {np.mean(x.data)}, std: {np.std(x.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> data/MNIST/raw/train-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-images-idx3-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/train-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-labels-idx1-ubyte already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists <<<\n",
      " >>> data/MNIST/raw/t10k-images-idx3-ubyte already exists <<<\n",
      ">>> applying ToTensor()...\n",
      " :O already a tensor\n",
      ">>> applying Normalize(mean=(0.5,), std=(0.5,)), inplace=True...\n",
      ">>> [ToTensor(), Normalize(mean=(0.5,), std=(0.5,)), inplace=True] applied successfully <<<\n"
     ]
    }
   ],
   "source": [
    "transformation=Compose([ToTensor(),Normalize((0.5,),(0.5,))])\n",
    "train_data=MNIST(root='data', train=True, download=True, transform=transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- example from our library:\n",
      "x type: <class 'tensor.Tensor'>, y type: <class 'tensor.Tensor'>\n",
      "x shape: (32, 1, 28, 28), y shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "print('-- example from our library:')\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "\n",
    "for x,y in train_loader:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    # print('data:', x)\n",
    "    # print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0 | x shape: (32, 1, 28, 28)  |  y: Tensor([0 6 6 2 8 1 7 9 4 9 7 1 1 9 9 0 6 6 0 0 4 7 9 6 3 8 1 8 8 7 8 7], requires_grad=False), type y: <class 'tensor.Tensor'>\n",
      "batch number: 1 | x shape: (32, 1, 28, 28)  |  y: Tensor([1 9 4 7 1 3 0 5 7 7 0 3 1 9 3 2 5 7 3 9 7 8 9 1 0 4 8 8 0 6 1 4], requires_grad=False), type y: <class 'tensor.Tensor'>\n",
      "batch number: 2 | x shape: (32, 1, 28, 28)  |  y: Tensor([7 7 6 1 6 3 5 9 2 6 8 4 5 2 2 2 8 0 1 7 9 0 7 6 7 4 0 7 5 5 0 1], requires_grad=False), type y: <class 'tensor.Tensor'>\n",
      "batch number: 3 | x shape: (32, 1, 28, 28)  |  y: Tensor([6 6 1 3 6 3 1 1 6 0 1 7 7 9 4 1 4 3 6 0 3 1 7 2 6 0 7 9 7 3 6 1], requires_grad=False), type y: <class 'tensor.Tensor'>\n",
      "batch number: 4 | x shape: (32, 1, 28, 28)  |  y: Tensor([7 5 6 2 5 1 9 4 8 9 6 9 6 7 4 7 3 3 6 2 3 3 2 9 8 9 0 5 2 5 8 8], requires_grad=False), type y: <class 'tensor.Tensor'>\n",
      "batch number: 5 | x shape: (32, 1, 28, 28)  |  y: Tensor([1 3 1 3 9 4 6 0 7 4 7 0 4 2 0 3 4 7 9 4 5 1 6 6 9 5 7 2 9 8 0 0], requires_grad=False), type y: <class 'tensor.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i,(x, y) in enumerate(train_loader):\n",
    "    print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- example from torch:\n",
      "x type: <class 'torch.Tensor'> and dtype: torch.float32, y type: <class 'torch.Tensor'>\n",
      "x shape: torch.Size([32, 1, 28, 28]), y shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print('-- example from torch:')\n",
    "torch_train_loader=torch.utils.data.DataLoader(torch_train_data, batch_size=32)\n",
    "\n",
    "for x,y in torch_train_loader:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    # print('data:', x)\n",
    "    # print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0 | x shape: torch.Size([32, 1, 28, 28])  |  y: tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8]), type y: <class 'torch.Tensor'>\n",
      "batch number: 1 | x shape: torch.Size([32, 1, 28, 28])  |  y: tensor([6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8,\n",
      "        0, 9, 4, 1, 4, 4, 6, 0]), type y: <class 'torch.Tensor'>\n",
      "batch number: 2 | x shape: torch.Size([32, 1, 28, 28])  |  y: tensor([4, 5, 6, 1, 0, 0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9,\n",
      "        0, 4, 6, 7, 4, 6, 8, 0]), type y: <class 'torch.Tensor'>\n",
      "batch number: 3 | x shape: torch.Size([32, 1, 28, 28])  |  y: tensor([7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n",
      "        2, 0, 2, 7, 1, 8, 6, 4]), type y: <class 'torch.Tensor'>\n",
      "batch number: 4 | x shape: torch.Size([32, 1, 28, 28])  |  y: tensor([1, 6, 3, 4, 5, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2, 8, 5, 8, 6, 7, 3, 4, 6,\n",
      "        1, 9, 9, 6, 0, 3, 7, 2]), type y: <class 'torch.Tensor'>\n",
      "batch number: 5 | x shape: torch.Size([32, 1, 28, 28])  |  y: tensor([8, 2, 9, 4, 4, 6, 4, 9, 7, 0, 9, 2, 9, 5, 1, 5, 9, 1, 2, 3, 2, 3, 5, 9,\n",
      "        1, 7, 6, 2, 8, 2, 2, 5]), type y: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i,(x, y) in enumerate(torch_train_loader):\n",
    "    print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "    if i==5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
