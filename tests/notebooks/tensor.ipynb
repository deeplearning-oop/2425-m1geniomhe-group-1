{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import Tensor\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- checking if a variable is a sequence\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "isinstance([1], collections.abc.Sequence) # a list is a sequence\n",
    "isinstance((1,), collections.abc.Sequence) # a tuple is a sequence\n",
    "isinstance('a', collections.abc.Sequence) # a string is a sequence\n",
    "isinstance(1, collections.abc.Sequence) # an int is not a sequence\n",
    "isinstance(1.0, collections.abc.Sequence) # a float is not a sequence\n",
    "isinstance(np.array([1,2,3]), collections.abc.Sequence) # a numpy array is NOT a sequence\n",
    "\n",
    "# -- checking if a variable is iterable\n",
    "\n",
    "isinstance([1], collections.abc.Iterable) # a list is iterable\n",
    "isinstance((1,), collections.abc.Iterable) # a tuple is iterable\n",
    "isinstance('a', collections.abc.Iterable) # a string is iterable\n",
    "isinstance(1, collections.abc.Iterable) # an int is not iterable\n",
    "isinstance(1.0, collections.abc.Iterable) # a float is not iterable\n",
    "isinstance(np.array([1,2,3]), collections.abc.Iterable) # a numpy array is iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when creating a tensor, need to 1st check the data type. We can give a list (which is recorgnaized as a seq), numpy array or a numeric (not recognized). Otherwise, to imitate pytorch, we can give an object of type `torch.Size` (in which case it would be names `lib.Size`, we have to create it ourselves) which returns an empty tensor of these dimensions\n",
    "\n",
    "When instanciating an object of type Tensor, we can give the following arguments as **data**:  \n",
    "\n",
    "- list of numbers of list of lists (the items at the end must be numbers, it could be list of list of list of list of numbers, etc)  \n",
    "- numpy array (not explicitly required to provide this functionality by the assignment, but might be useful when importing, tranforming and processing data)  \n",
    "- numeric (only really required to handle int32, int64, float32, float64), these numerci types should be defined in the library to imitate pytorch ui  \n",
    "\n",
    "Need to validate for these types when creating a tensor (could be in `__setattr__` method of Tensor class OR could be handlede within the tensor() function since we want to make the user create the tensor through it, as it is the case in pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2,3])\n",
    "t1.dtype #by default it is int64 \n",
    "\n",
    "t2 = torch.tensor([1.0,2])\n",
    "t2.dtype #by default it is float32\n",
    "\n",
    "t1.requires_grad #by default it is False\n",
    "\n",
    "t1.is_leaf #by default it is True\n",
    "\n",
    "# t3=torch.tensor() #this will raise an error, need to have arg data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behaviour of the `tensor()` function:  \n",
    "\n",
    "* at least oen require argument, the data  \n",
    "* if elements in the lowest level are not numbers, raise an error  \n",
    "* if elements in the lowest level are numbers and one of them is a float, the tensor should be of type float32 otherwise int64 (if no dtype is provided)  \n",
    "\n",
    "_the Tensor class is deprecated, pytorch recommends using the torch.tensor() function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'torch',\n",
       "              '__repr__': <slot wrapper '__repr__' of 'torch.dtype' objects>,\n",
       "              '__reduce__': <method '__reduce__' of 'torch.dtype' objects>,\n",
       "              'to_real': <method 'to_real' of 'torch.dtype' objects>,\n",
       "              'to_complex': <method 'to_complex' of 'torch.dtype' objects>,\n",
       "              'is_floating_point': <attribute 'is_floating_point' of 'torch.dtype' objects>,\n",
       "              'is_complex': <attribute 'is_complex' of 'torch.dtype' objects>,\n",
       "              'is_signed': <attribute 'is_signed' of 'torch.dtype' objects>,\n",
       "              'itemsize': <attribute 'itemsize' of 'torch.dtype' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.float32) #torch.dtype\n",
    "# type(torch.dtype) #type\n",
    "\n",
    "# issubclass(torch.float32, torch.dtype) #this will raise an error, torch.float32 is not a class\n",
    "isinstance(torch.float32, torch.dtype)\n",
    "\n",
    "# torch.dtype.__dict__\n",
    "# torch.float32.__dict__ #AttributeError: 'torch.dtype' object has no attribute '__dict__'\n",
    "\n",
    "# torch.float32(1) #not callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=torch.tensor([1,2,3])\n",
    "t1[0] #tensor(1), returns a tensor object with 1st item in the tensor (if it is a scalar, it will return a 0D tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor is an iterable of tensors, where the lowest level that isn't iterable is teh 0 dimensional tensor (scalar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Tensor([1,2])==torch.tensor([1.0,2.0])) #tensor([True, True]), this output is of type Tensor TAKE INTO CONSIDERATION WHEN WRITING THE __eq__ method\n",
    "isinstance(torch.tensor([1,2]), torch.Tensor) # True\n",
    "\n",
    "# -- torch.tensor(-) is a function that instanciates an object of type torch.Tensor and returns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True, False])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1=torch.tensor([1,2,3,3])\n",
    "t2=torch.tensor([1.0,2.0,3.0,5])\n",
    "t1==t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar has ndim=0, shape (Size) empty, so it's a 0D tensor  \n",
    "A scalar is defined when we give a single number (so numeric type) to the tensor constructor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar = torch.tensor(7.)\n",
    "scalar=torch.tensor(int(7.0))\n",
    "scalar=torch.tensor(float(7))\n",
    "scalar=torch.tensor(np.int64(7)) #alright\n",
    "# scalar=torch.tensor('a') #TypeError: new(): invalid data type 'str'\n",
    "scalar\n",
    "\n",
    "isnumeric = lambda x: isinstance(x, (int, float, np.int64, np.float64,np.int32, np.float32))\n",
    "isnumeric(scalar.item()) \n",
    "# type(scalar.item()) #int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of dim:0; dim:torch.Size([]); size:torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(f'nb of dim:{scalar.ndim}; dim:{scalar.shape}; size:{scalar.size()}')\n",
    "\n",
    "# help(Tensor.size) \n",
    "# -- the difference between size() and shape is that size(), we can give it a dimension and it will return the size of that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(scalar)\n",
    "#TypeError: len() of a 0-d tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of dim:1; dim:torch.Size([3]); size:torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "vector=torch.tensor([1,2,3])\n",
    "vector=torch.tensor([1.,2.,3.])\n",
    "vector=torch.tensor([1,2,3], dtype=torch.float32)\n",
    "# vector=torch.tensor(np.array([1,2,3])) #works fine :')\n",
    "\n",
    "print(f'nb of dim:{vector.ndim}; dim:{vector.shape}; size:{vector.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# type(vector.shape)\n",
    "# help(torch.Size())\n",
    "\n",
    "vec2=torch.tensor([1,2,3], requires_grad=True,dtype=torch.float32) #requires_grad=True only if float\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.requires_grad #true\n",
    "vector.requires_grad #false\n",
    "\n",
    "vector.dtype #int64 by default\n",
    "\n",
    "vec2==vector \n",
    "#returns tensor([True, True, True]) so __eq__ only looks up values (no dtype, requires_grad, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2==scalar\n",
    "scalar==vec2\n",
    "# both return tensor([False, False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of dim:2; dim:torch.Size([2, 3]); size:torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "matrix=torch.tensor([[1,2,3],[4,5,6]])\n",
    "matrix=torch.tensor([[1.,2.,3.],[4.,5.,6.]])\n",
    "# matrix=torch.tensor([[1,2,3],[4,5]]) #ValueError: expected sequence of length 3 at dim 1 (got 2)\n",
    "# -- this means that items has to be of the same length at each level of the list\n",
    "\n",
    "print(f'nb of dim:{matrix.ndim}; dim:{matrix.shape}; size:{matrix.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of dim:3; dim:torch.Size([2, 2, 2]); size:torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "t3d=torch.tensor([\n",
    "        [\n",
    "            [1,2],\n",
    "            [3,4]\n",
    "        ],\n",
    "        [\n",
    "            [5,6],\n",
    "            [7,8]\n",
    "        ]\n",
    "    ])\n",
    "# <=>\n",
    "t3d=torch.tensor(np.array([\n",
    "        [\n",
    "            [1,2],\n",
    "            [3,4]\n",
    "        ],\n",
    "        [\n",
    "            [5,6],\n",
    "            [7,8]\n",
    "        ]\n",
    "    ]))\n",
    "\n",
    "print(f'nb of dim:{t3d.ndim}; dim:{t3d.shape}; size:{t3d.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we give it a list of lists, notice that the ndim=number of opened brackets, and the shape is the number of elements in each bracket.  \n",
    "Othweise if np array, it's easier to process dimensions as we can use the `shape` attribute of the numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "\n",
    "scalar=torch.tensor(7)\n",
    "vector=torch.tensor([1,2,3])\n",
    "matrix=torch.tensor([[1,2,3],[4,5,6]])\n",
    "t3d=torch.tensor([\n",
    "        [\n",
    "            [1,2],\n",
    "            [3,4],\n",
    "            [5,6],\n",
    "            [7,8]\n",
    "        ],\n",
    "        [\n",
    "            [9,10],\n",
    "            [11,12],\n",
    "            [13,14],\n",
    "            [15,16]\n",
    "        ],\n",
    "        [\n",
    "            [17,18],\n",
    "            [19,20],\n",
    "            [21,22],\n",
    "            [23,24]\n",
    "        ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar: 7\n",
      "vector: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# transpose:\n",
    "\n",
    "print(f'scalar: {scalar.T}') #/tmp/ipykernel_3772/88739345.py:3: UserWarning: Tensor.T is deprecated on 0-D tensors. This function is the identity in these cases. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3691.)\n",
    "# print(scalar.T)\n",
    "\n",
    "print(f'vector: {vector.T}') #tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix: tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "before: torch.Size([2, 3]); after: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f'matrix: {matrix.T}') #tensor([[1, 4],\n",
    "#         [2, 5],\n",
    "#         [3, 6]])\n",
    "print(f'before: {matrix.shape}; after: {matrix.T.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3d: tensor([[[ 1,  9, 17],\n",
      "         [ 3, 11, 19],\n",
      "         [ 5, 13, 21],\n",
      "         [ 7, 15, 23]],\n",
      "\n",
      "        [[ 2, 10, 18],\n",
      "         [ 4, 12, 20],\n",
      "         [ 6, 14, 22],\n",
      "         [ 8, 16, 24]]])\n",
      "before: torch.Size([3, 4, 2]); after: torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f't3d: {t3d.T}')\n",
    "print(f'before: {t3d.shape}; after: {t3d.T.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  9 17]\n",
      "  [ 3 11 19]\n",
      "  [ 5 13 21]\n",
      "  [ 7 15 23]]\n",
      "\n",
      " [[ 2 10 18]\n",
      "  [ 4 12 20]\n",
      "  [ 6 14 22]\n",
      "  [ 8 16 24]]]\n",
      "before: (3, 4, 2); after: (2, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "np3d=np.array(t3d)\n",
    "print(np3d.T)\n",
    "print(f'before: {np3d.shape}; after: {np3d.T.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 14, 21],\n",
       "        [28, 35, 42]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar=torch.tensor(7)\n",
    "vector=torch.tensor([1,2,3])\n",
    "matrix=torch.tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "scalar*vector\n",
    "vector*scalar\n",
    "vector*matrix\n",
    "matrix*vector\n",
    "scalar*matrix\n",
    "matrix * scalar\n",
    "#all of these cases work, which are element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [ 4, 10, 18]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.mul(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [3, 3] but got: [3, 4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m t3d\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      2\u001b[0m         [\n\u001b[1;32m      3\u001b[0m             [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         ]\n\u001b[1;32m     20\u001b[0m     ])\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmatrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt3d\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [3, 3] but got: [3, 4]."
     ]
    }
   ],
   "source": [
    "t3d=torch.tensor([\n",
    "        [\n",
    "            [1,2],\n",
    "            [3,4],\n",
    "            [5,6],\n",
    "            [7,8]\n",
    "        ],\n",
    "        [\n",
    "            [9,10],\n",
    "            [11,12],\n",
    "            [13,14],\n",
    "            [15,16]\n",
    "        ],\n",
    "        [\n",
    "            [17,18],\n",
    "            [19,20],\n",
    "            [21,22],\n",
    "            [23,24]\n",
    "        ]\n",
    "    ])\n",
    "\n",
    "matrix @ t3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave an error so it's not always the case that we can multiply items of different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: torch.Size([2, 3]); torch.Size([3, 2]); torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# multiplying tensors\n",
    "t=torch.tensor([1,2,3])\n",
    "t1=torch.tensor([1,2,3])\n",
    "\n",
    "t*t1 #tensor([1, 4, 9]) #element-wise multiplication\n",
    "\n",
    "matrix1=torch.tensor([[1,2,3],[4,5,6]])\n",
    "matrix2=torch.tensor([[1,2],[3,4],[5,6]])\n",
    "# matrix1 * matrix2 #RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n",
    "# THIS IS BECAUSE * IS ELEMENT-WISE MULTIPLICATION\n",
    "\n",
    "# matrix multiplication\n",
    "torch.matmul(matrix1, matrix2) #tensor([[22, 28],[49, 64]])\n",
    "print(f'shapes: {matrix1.shape}; {matrix2.shape}; {torch.matmul(matrix1, matrix2).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1.matmul(matrix2)\n",
    "#both matrix.matmul and torch.matmul work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1.mm(matrix2) #tensor([[22, 28],[49, 64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 @ matrix2 #tensor([[22, 28],[49, 64]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can do either `torch.matmul()` or `@` or `torch.mm()` to perform tensor multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [x] dtype \n",
    "* [ ] validation (raise errors if conditions are not met):  \n",
    "    * the input data type (has to be list, numpy array at top level; numeric type exceptionally when defining a 0D tensor)   \n",
    "    * no empty lists  \n",
    "    * the lowest level of the data (has to be numeric), convert by default to float64 using python's `float()` casting function  \n",
    "    * the dimensions are uniform at each level  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class dtype(Enum):\n",
    "    int64 = \"int64\"\n",
    "    float64 = \"float64\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.value\n",
    "\n",
    "    def __call__(self, x):\n",
    "        '''make if callable, uses:\n",
    "        ```\n",
    "        >>> dtype.int64(1.7)\n",
    "        1\n",
    "        >>> dtype.float64(1)\n",
    "        1.0\n",
    "        '''\n",
    "        if self == dtype.int64:\n",
    "            return int(x)\n",
    "        elif self == dtype.float64:\n",
    "            return float(x)\n",
    "        else:\n",
    "            print(f\"Unknown dtype: {self}\")\n",
    "\n",
    "# -- aliasing\n",
    "int64 = dtype.int64\n",
    "float64 = dtype.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'dtype'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=dtype.int64\n",
    "type(d) #<enum 'dtype'>\n",
    "isinstance(d, dtype) #True\n",
    "isinstance(d, Enum) #True\n",
    "isinstance(d, type) #False\n",
    "type(d) #<enum 'dtype'>\n",
    "type(dtype) #enum.EnumType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_emptylist(1) #False\n",
    "# l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emptylist(l):\n",
    "    '''\n",
    "    returns True if l has at the lowest level at least one empty list\n",
    "    \n",
    "    e.g.\n",
    "\n",
    "    ```\n",
    "    >>> is_emptylist([])\n",
    "    True\n",
    "    >>> is_emptylist([1])\n",
    "    False\n",
    "    >>> is_emptylist(1)  \n",
    "    False\n",
    "    >>> is_emptylist([[]])\n",
    "    True\n",
    "    >>> is_emptylist([[],[]])  \n",
    "    True\n",
    "    >>> is_emptylist([[],[1]])\n",
    "    True\n",
    "    >>> is_emptylist([[1,2],[1,2]])\n",
    "    False\n",
    "    ```\n",
    "    '''\n",
    "    if isinstance(l, list):\n",
    "        if not l:  \n",
    "            return True\n",
    "        return any(is_emptylist(x) for x in l)  #recursive call\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_numeric(x):\n",
    "    '''\n",
    "    takes x and returns True if x is a numeric type \n",
    "    \n",
    "    e.g.\n",
    "\n",
    "    ```\n",
    "    >>> is_numeric(1)\n",
    "    True\n",
    "    >>> is_numeric(1.0)\n",
    "    True\n",
    "    >>> is_numeric('a')\n",
    "    False\n",
    "    >>> is_numeric([1])\n",
    "    False\n",
    "    ```\n",
    "    '''\n",
    "    acceptable_numeric_types = (int, float, np.int64, np.float64, np.int32, np.float32)\n",
    "    for i in acceptable_numeric_types:\n",
    "        if isinstance(x, i):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_inner_numeric(l:list):\n",
    "    '''\n",
    "    recursive function that takes a list l and returns True if all the inner elements of l are numeric (depends on is_numeric())\n",
    "\n",
    "    e.g.\n",
    "\n",
    "    ```\n",
    "    >>> is_inner_numeric([1,2,3])\n",
    "    True\n",
    "    >>> is_inner_numeric([1,2,'a'])\n",
    "    False\n",
    "    >>> is_inner_numeric([1,[2,3]])\n",
    "    True\n",
    "    >>> is_inner_numeric([1,[2,'a']])\n",
    "    False\n",
    "    ```\n",
    "    '''\n",
    "    if isinstance(l,list):\n",
    "        return all(is_inner_numeric(x) for x in l)\n",
    "    else:\n",
    "        return is_numeric(l)\n",
    "    \n",
    "def check_dlist(l):\n",
    "    '''makes sure the input is either a numeric or a non empty dlist of numerics, depends on is_inner_numeric() and is_numeric() and is_emptylist()\n",
    "\n",
    "    THROW ValueError if the input is not a numeric or a dlist of numerics\n",
    "    \n",
    "    '''\n",
    "    if is_emptylist(l):\n",
    "        raise ValueError('empty list provided')\n",
    "    if not is_inner_numeric(l):\n",
    "        raise ValueError('all elements in the list must be numeric')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### TESTING #####\n",
    "# #wont use them will use cast_dtype instead :p\n",
    "\n",
    "\n",
    "# def make_float64(l):\n",
    "#     '''\n",
    "#     recursive function that takes a list l and returns a list with all the numeric elements converted to float64\n",
    "\n",
    "#     note: this step is after checking if the elements are numeric\n",
    "    \n",
    "#     e.g.\n",
    "\n",
    "#     ```\n",
    "#     >>> make_float64([1,2,3])\n",
    "#     [1.0, 2.0, 3.0]\n",
    "#     >>> make_float64([1,2])  \n",
    "#     [1.0, 2.0]\n",
    "#     >>> make_float64([1,2.0])\n",
    "#     [1.0, 2.0]\n",
    "#     >>> make_float64([1,[2,3]])\n",
    "#     [1.0, [2.0, 3.0]]\n",
    "#     ```\n",
    "#     '''\n",
    "#     if isinstance(l,list):\n",
    "#         return [make_float64(x) for x in l]\n",
    "#     else:\n",
    "#         return float(l)\n",
    "\n",
    "# def make_int64(l):\n",
    "#     '''\n",
    "#     recursive function that takes a list l and returns a list with all the numeric elements converted to int64\n",
    "\n",
    "#     note: this step is after checking if the elements are numeric\n",
    "    \n",
    "#     e.g.\n",
    "\n",
    "#     ```\n",
    "#     >>> make_int64([1.0,2.0,3.0])\n",
    "#     [1, 2, 3]\n",
    "#     >>> make_int64([1.0,2.0])  \n",
    "#     [1, 2]\n",
    "#     >>> make_int64([1.0,2])\n",
    "#     [1, 2]\n",
    "#     >>> make_int64([1,[2.0,3.0]])\n",
    "#     [1, [2, 3]]\n",
    "#     ```\n",
    "#     '''\n",
    "#     if isinstance(l,list):\n",
    "#         return [make_int64(x) for x in l]\n",
    "#     else:\n",
    "#         return int(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to go recursively to teh lowest level of the list: we'll use a function deorator\n",
    "\n",
    "\n",
    "# def memoize_dimensions(func):\n",
    "#     \"\"\"decorator to memoize the dimensions of a nested list\"\"\"\n",
    "#     cache = {}\n",
    "\n",
    "#     def inner(nested_list):\n",
    "#\n",
    "#         id_list = id(nested_list)\n",
    "#         if id_list in cache:\n",
    "#             return cache[id_list]\n",
    "#         result = func(nested_list)\n",
    "#         cache[id_list] = result\n",
    "#         return result\n",
    "#\n",
    "#     return inner\n",
    "\n",
    "# @memoize_dimensions\n",
    "def infer_dimensions(nested_list):\n",
    "    '''\n",
    "    recursively infer the dimensions of a nested list and validate uniformity  \n",
    "\n",
    "    THROW ERROR IF NOT UNIFORM\n",
    "\n",
    "    ```\n",
    "    >>> infer_dimensions([1,2,3]) #vector\n",
    "    [3]\n",
    "    >>> infer_dimensions([1]) #vector\n",
    "    [1]\n",
    "    >>> infer_dimensions(1)  #scalar\n",
    "    []  \n",
    "    >>> infer_dimensions([[1,2],[3,4]]) #matrix\n",
    "    [2, 2]  \n",
    "    >>> infer_dimensions([[[1,2],[3,4]],[[5,6],[7,8]]]) #3D tensor\n",
    "    [2, 2, 2]  \n",
    "    >>> infer_dimensions([[[1,2],[3,4]],[[5,6],[7]]]) \n",
    "    ValueError: Dimension mismatch detected: [[2, 2], [2, 1]]\n",
    "    '''\n",
    "    if isinstance(nested_list, list):\n",
    "        if len(nested_list) == 0: #if empty inner list = dimension 0\n",
    "            'base case for scalars, reurn dim 0'\n",
    "            return [0]  \n",
    "        sub_shapes = [infer_dimensions(sublist) for sublist in nested_list]\n",
    "        if len(set(map(tuple, sub_shapes))) > 1:  \n",
    "            '''\n",
    "            # this condition takes all shapes of lists at the same level which are lists inside sub_shapes\n",
    "            # makes them tuples and remove duplicates (set())\n",
    "            # length should be 1 if the lists are uniform in shape\n",
    "            '''\n",
    "            raise ValueError(f\"Dimension mismatch detected: {sub_shapes}\")\n",
    "    \n",
    "        return [len(nested_list)] + sub_shapes[0]  #combine this level with sub-dimensions so this way we have [2,2] for [[1,2],[3,4]] (sub_shapes[0] is the only item in the list)\n",
    "    \n",
    "    #if not a list (a scalar), no dimensions, need to return a list of length 0 in order to check for at the next base case\n",
    "    return [] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: [2, 2]\n",
      "Error: Dimension mismatch detected: [[2], [3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    nested_list = [[1, 2], [3, 4]]\n",
    "    dimensions = infer_dimensions(nested_list)\n",
    "    print(\"Dimensions:\", dimensions)\n",
    "\n",
    "    irregular_list = [[1, 2], [3, 4, 5]]\n",
    "    infer_dimensions(irregular_list)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples to test\n",
    "\n",
    "l0=1\n",
    "l1=[1,2,3,4]\n",
    "l2=[[1,2],[3,4]]\n",
    "l3=[[[1,2],[3,4]],[[5,6],[7,8]]]\n",
    "l4=[[\n",
    "        [1,2],[3,4],[5,6],[7,8],[9,10],[11,12]\n",
    "    ],\n",
    "    [\n",
    "        [5,6],[7,8],[9,10],[11,12],[13,14],[15,16]\n",
    "    ], \n",
    "    [\n",
    "        [9,10],[11,12],[13,14],[15,16],[17,18],[19,20]\n",
    "    ]]\n",
    "\n",
    "l5=[\n",
    "    [\n",
    "        [\n",
    "            [1,2],[3,4]\n",
    "        ],\n",
    "        [\n",
    "            [5,6],[7,8]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "#empty\n",
    "bad_l0=[]\n",
    "#same level but one list and one int\n",
    "bad_l1=[1,[1]] \n",
    "#non uniform length at same level\n",
    "bad_l2=[[1,2],[3]]\n",
    "bad_l3=[[[1,2],[3,4]],[[5,6],[7]]]\n",
    "bad_l4=[[[1,2],[3,4]],[[5,6],[7,8],[9,10]]]\n",
    "#not enclosed by list at top level\n",
    "bad_l5=(1,2)\n",
    "#lowest level not numeric\n",
    "bad_l6=[[[1,2],[3,4]],[[5,6],[7,'a']]]\n",
    "\n",
    "# is_numeric(bad_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_emptylist(bad_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Dimension mismatch detected: [[2, 2], [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    d=infer_dimensions(bad_l4)\n",
    "    print(d)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "# successful test\n",
    "\n",
    "# -- things that are not validated by infer_dimensions\n",
    "#   - the top level is a list  (handled in 1st step by checking the input type)\n",
    "#   - the lowest level is numeric   \n",
    "#   - the list is empty\n",
    "# need to add these checks prior to calling infer_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_dtype(nested_list, dt: dtype=dtype.float64):\n",
    "    '''\n",
    "    recursively cast the elements of a nested list to a given dtype (default is float64)\n",
    "\n",
    "    e.g.\n",
    "    \n",
    "    ```\n",
    "    >>> cast_dtype([1,2,3], dtype.float64)\n",
    "    [1.0, 2.0, 3.0]\n",
    "    >>> cast_dtype([1,2,3], dtype.int64)\n",
    "    [1, 2, 3]\n",
    "    ```\n",
    "    '''\n",
    "    if isinstance(nested_list, list):\n",
    "        return [cast_dtype(sublist, dt) for sublist in nested_list]\n",
    "    return dt(nested_list)\n",
    "\n",
    "\n",
    "#successful test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dtype(dt):\n",
    "    '''\n",
    "    check if dtype is within the dtype enumerate\n",
    "\n",
    "    ```\n",
    "    >>> check_dtype('int64')\n",
    "    >>> check_dtype('int32')\n",
    "    ValueError: Invalid dtype given: int32; Valid dtypes are from ['int64', 'float64'] #so far, under development\n",
    "    ```\n",
    "    '''\n",
    "    if dt not in dtype.__members__.keys():\n",
    "        raise ValueError(f\"Invalid dtype given: {dtype}; Valid dtypes are from {list(dtype.__members__.keys())}\")\n",
    "    \n",
    "    return dtype.__members__[dt]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]],\n",
       " [[5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]],\n",
       " [[9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_dtype(l4, check_dtype('float64'))\n",
    "\n",
    "dt=check_dtype('int64')\n",
    "cast_dtype(l4, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tensor_input(input_data):\n",
    "    '''\n",
    "    The input should be either a numeric or a nested list of numerics (allow for numpy in later versions)\n",
    "\n",
    "    When validating the things to check for (in order) are:  \n",
    "\n",
    "    1. if the input is a  non-empty list (could be nested) (or numeric): raise ValueError if not -> check_dlist(input_data)    \n",
    "    2. dimensions of the list (uniformity): raise valueError if not uniform -> infer_dimensions(input_data)  \n",
    "\n",
    "    in 1 we are checking for (when non numeric):  \n",
    "        a. top level is a list   \n",
    "        b. non-empty list (nor containing empty lists)  \n",
    "        c. lowest level is numeric    \n",
    "    '''\n",
    "    try:\n",
    "        check_dlist(input_data)\n",
    "        dimensions=infer_dimensions(input_data)\n",
    "        return dimensions #or maybe just assign them in the class\n",
    "    except ValueError as e:\n",
    "        print(\"ValueError: InputData\", e)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: InputData all elements in the list must be numeric\n"
     ]
    }
   ],
   "source": [
    "validate_tensor_input(bad_l6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrix ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0], [3.0, 4.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_ndarray= lambda l: np.array(l)\n",
    "ndarray_to_list= lambda a: a.tolist()\n",
    "\n",
    "list_to_ndarray([1,2,3]) #all int\n",
    "list_to_ndarray([[1.0,2],[3,4]]) #all float\n",
    "ndarray_to_list(np.array([[1,2],[3,4]])) #all int\n",
    "ndarray_to_list(np.array([[1,2.0],[3,4]])) #all float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dtype(instance1, instance2):\n",
    "    if instance1.dtype=='float64':\n",
    "        instance2.dtype='float64'  \n",
    "    elif instance2.dtype=='float64':\n",
    "        instance1.dtype='float64'\n",
    "    else:\n",
    "        print('both instances of the same dtype')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[1], [5], [9]], [[3], [7], [11]]], [[[2], [6], [10]], [[4], [8], [12]]]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transpose(l:list):\n",
    "    '''\n",
    "    a function to transpose a list (2 or more dimensions) \n",
    "\n",
    "    ### params:\n",
    "        * l: list to transpose\n",
    "    ### returns:\n",
    "        * transposed list\n",
    "\n",
    "    it does this operation through an ndarray intermediary\n",
    "\n",
    "    this will be used in the T method of the tensor class, making these 2 ops equivalent:  \n",
    "\n",
    "    ```\n",
    "    >>> transpose([[1,2],[3,4]])\n",
    "    [[1, 3], [2, 4]]\n",
    "    >>> t=tensor([[1,2],[3,4]])\n",
    "    >>> t.T\n",
    "    [[1, 3], [2, 4]]\n",
    "    ```\n",
    "\n",
    "    '''\n",
    "    ndarray=list_to_ndarray(l)\n",
    "    transposed=ndarray.T\n",
    "    return ndarray_to_list(transposed)\n",
    "\n",
    "transpose([[1,2],[3,4]])\n",
    "transpose([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "transpose([\n",
    "    [\n",
    "        [\n",
    "            [1,2],[3,4]\n",
    "        ],\n",
    "        [\n",
    "            [5,6],[7,8]\n",
    "        ],\n",
    "        [\n",
    "            [9,10],[11,12]\n",
    "        ]\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-2.5, -5.0], [-7.5, -10.0]], [[-12.5, -15.0], [-17.5, -20.0]]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #dont wanna use it, will use numpy\n",
    "\n",
    "# def scalar_multiply(l:list, scalar):\n",
    "#     '''\n",
    "#     a function to multiply a list by a scalar (2 or more dimensions) \n",
    "\n",
    "#     ### params:\n",
    "#         * l: list to multiply\n",
    "#         * scalar: scalar to multiply by\n",
    "#     ### returns:\n",
    "#         * multiplied list\n",
    "\n",
    "#     it does this operation through an ndarray intermediary\n",
    "\n",
    "#     this will be used in the * method of the tensor class, making these 2 ops equivalent:  \n",
    "\n",
    "#     ```\n",
    "#     >>> scalar_multiply([[1,2],[3,4]], 2)\n",
    "#     [[2, 4], [6, 8]]\n",
    "#     >>> t=tensor([[1,2],[3,4]])\n",
    "#     >>> t*2\n",
    "#     [[2, 4], [6, 8]]\n",
    "#     ```\n",
    "\n",
    "#     '''\n",
    "#     ndarray=list_to_ndarray(l)\n",
    "#     multiplied=ndarray*scalar\n",
    "#     return ndarray_to_list(multiplied)\n",
    "\n",
    "# scalar_multiply([[1,2],[3,4]], 2)\n",
    "# scalar_multiply([[[1,2],[3,4]],[[5,6],[7,8]]], -2.5) #need to pay attention if dtype is float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4], [9, 16]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def element_wise_multiply(l1, l2):\n",
    "    '''\n",
    "    a function to multiply 2 lists, element-wise\n",
    "\n",
    "    ### params:\n",
    "        * l1: list 1\n",
    "        * l2: list 2\n",
    "    ### returns:\n",
    "        * multiplied list\n",
    "\n",
    "    it does this operation through an ndarray intermediary\n",
    "\n",
    "    this will be used in the * method of the tensor class (__mul__), making these 2 ops equivalent:  \n",
    "\n",
    "    ```\n",
    "    >>> multiply([[1,2],[3,4]], [[1,2],[3,4]])\n",
    "    [[1, 4], [9, 16]]\n",
    "    >>> t1=tensor([[1,2],[3,4]])\n",
    "    >>> t2=tensor([[1,2],[3,4]])\n",
    "    >>> t1*t2\n",
    "    [[1, 4], [9, 16]]\n",
    "    ```\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ndarray1=list_to_ndarray(l1)\n",
    "    ndarray2=list_to_ndarray(l2)\n",
    "    multiplied=ndarray1*ndarray2\n",
    "    return ndarray_to_list(multiplied)\n",
    "\n",
    "l1=[[1,2],[3,4]]\n",
    "l2=[[1,2],[3,4]]\n",
    "element_wise_multiply(l1,l2)\n",
    "element_wise_multiply(l1,4.0)\n",
    "element_wise_multiply(l1,[[1,2],[3,4]]) #element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 12, 15], [19, 26, 33], [29, 40, 51]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matrix_multiply(l1, l2):\n",
    "    '''\n",
    "    a function to multiply 2 matrices\n",
    "\n",
    "    ### params:\n",
    "        * l1: matrix 1\n",
    "        * l2: matrix 2\n",
    "    ### returns:\n",
    "        * multiplied matrix\n",
    "\n",
    "    it does this operation through an ndarray intermediary\n",
    "\n",
    "    this will be used in the @ method of the tensor class (__matmul__), making these 2 ops equivalent:  \n",
    "\n",
    "    ```\n",
    "    >>> matrix_multiply([[1,2],[3,4]], [[1,2],[3,4]])\n",
    "    [[7, 10], [15, 22]]\n",
    "    >>> t1=tensor([[1,2],[3,4]])\n",
    "    >>> t2=tensor([[1,2],[3,4]])\n",
    "    >>> t1@t2\n",
    "    [[7, 10], [15, 22]]\n",
    "    ```\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ndarray1=list_to_ndarray(l1)\n",
    "    ndarray2=list_to_ndarray(l2)\n",
    "    multiplied=ndarray1@ndarray2\n",
    "    return ndarray_to_list(multiplied)\n",
    "\n",
    "l1=[[1,2],[3,4]]\n",
    "l2=[[1,2],[3,4]]\n",
    "matrix_multiply(l1,l2)\n",
    "matrix_multiply([[1,2],[3,4],[5,6]],[[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our pytorch-wannabe lib code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "\n",
    "from tensor import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim:0; shape:[]; no size function created\n",
      "ndim:1; shape:[3]; no size function created\n",
      "ndim:2; shape:[2, 2]; no size function created\n"
     ]
    }
   ],
   "source": [
    "# -- testing the tensor class: successful tests (= torch)\n",
    "scalar=tensor(1)\n",
    "print(f'ndim:{scalar.ndim}; shape:{scalar.shape}; no size function created')\n",
    "\n",
    "vector=tensor([1,2,3])\n",
    "print(f'ndim:{vector.ndim}; shape:{vector.shape}; no size function created')\n",
    "\n",
    "matrix=tensor([[1,2],[3,4]])\n",
    "print(f'ndim:{matrix.ndim}; shape:{matrix.shape}; no size function created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- successful, reason why dtype default is different is explained in the readme\n",
    "t1 = tensor([1,2,3])\n",
    "t1.dtype #by default it is int64 in pytorch, here its float64 \n",
    "\n",
    "t2 = tensor([1.0,2])\n",
    "t2.dtype #by default it is float32 in pytorch here its float64\n",
    "\n",
    "t1.requires_grad #by default it is False exactly like in pytorch\n",
    "\n",
    "t1.is_leaf #by default it is True exactly like in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing different data inputs\n",
    "\n",
    "# examples to test\n",
    "\n",
    "l0=1\n",
    "l1=[1,2,3,4]\n",
    "l2=[[1,2],[3,4]]\n",
    "l3=[[[1,2],[3,4]],[[5,6],[7,8]]]\n",
    "l4=[[\n",
    "        [1,2],[3,4],[5,6],[7,8],[9,10],[11,12]\n",
    "    ],\n",
    "    [\n",
    "        [5,6],[7,8],[9,10],[11,12],[13,14],[15,16]\n",
    "    ], \n",
    "    [\n",
    "        [9,10],[11,12],[13,14],[15,16],[17,18],[19,20]\n",
    "    ]]\n",
    "\n",
    "l5=[\n",
    "    [\n",
    "        [\n",
    "            [1,2],[3,4]\n",
    "        ],\n",
    "        [\n",
    "            [5,6],[7,8]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "#empty\n",
    "bad_l0=[]\n",
    "#same level but one list and one int\n",
    "bad_l1=[1,[1]] \n",
    "#non uniform length at same level\n",
    "bad_l2=[[1,2],[3]]\n",
    "bad_l3=[[[1,2],[3,4]],[[5,6],[7]]]\n",
    "bad_l4=[[[1,2],[3,4]],[[5,6],[7,8],[9,10]]]\n",
    "#not enclosed by list at top level\n",
    "bad_l5=(1,2)\n",
    "#lowest level not numeric\n",
    "bad_l6=[[[1,2],[3,4]],[[5,6],[7,'a']]]\n",
    "\n",
    "good_lists=[l0,l1,l2,l3,l4,l5]\n",
    "bad_lists=[bad_l0,bad_l1,bad_l2,bad_l3,bad_l4,bad_l5,bad_l6]\n",
    "\n",
    "# is_numeric(bad_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "good list: 1\n",
      "\tndim:0; shape:[]; no size function created\n",
      "\n",
      "good list: [1, 2, 3, 4]\n",
      "\tndim:1; shape:[4]; no size function created\n",
      "\n",
      "good list: [[1, 2], [3, 4]]\n",
      "\tndim:2; shape:[2, 2]; no size function created\n",
      "\n",
      "good list: [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
      "\tndim:3; shape:[2, 2, 2]; no size function created\n",
      "\n",
      "good list: [[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]], [[5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]], [[9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]]]\n",
      "\tndim:3; shape:[3, 6, 2]; no size function created\n",
      "\n",
      "good list: [[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]]\n",
      "\tndim:4; shape:[1, 2, 2, 2]; no size function created\n"
     ]
    }
   ],
   "source": [
    "# successful: pytorch tensor\n",
    "\n",
    "for i in good_lists:\n",
    "    print(f'')\n",
    "    t=tensor(i)\n",
    "    print(f'good list: {i}\\n\\tndim:{t.ndim}; shape:{t.shape}; no size function created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ValueError: inputData empty list provided\n",
      "bad list: Tensor([],float64)\n",
      "\tndim:0; shape:None; no size function created\n",
      "\n",
      "ValueError: inputData dimension mismatch detected: [[], [1]]\n",
      "bad list: Tensor([1.0, [1.0]],float64)\n",
      "\tndim:0; shape:None; no size function created\n",
      "\n",
      "ValueError: inputData dimension mismatch detected: [[2], [1]]\n",
      "bad list: Tensor([[1.0, 2.0], [3.0]],float64)\n",
      "\tndim:0; shape:None; no size function created\n",
      "\n",
      "ValueError: inputData dimension mismatch detected: [[2], [1]]\n",
      "bad list: Tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0]]],float64)\n",
      "\tndim:0; shape:None; no size function created\n",
      "\n",
      "ValueError: inputData dimension mismatch detected: [[2, 2], [3, 2]]\n",
      "bad list: Tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0], [9.0, 10.0]]],float64)\n",
      "\tndim:0; shape:None; no size function created\n",
      "\n",
      "ValueError: inputData all elements in the LIST must be NUMERIC\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m bad_lists:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     t\u001b[38;5;241m=\u001b[39m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad list: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mndim:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; shape:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; no size function created\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/g/my_stuff/masters/saclay/courses/M1/Object-Orietnted Programming/project/tests/notebooks/../modules/tensor.py:618\u001b[0m, in \u001b[0;36mtensor\u001b[0;34m(data, dtype, requires_grad, is_leaf)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(data, dtype\u001b[38;5;241m=\u001b[39mfloat64, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    Factory function, generates a tensor instance instead of calling the class,  \u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    imitates the torch.tensor() function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/g/my_stuff/masters/saclay/courses/M1/Object-Orietnted Programming/project/tests/notebooks/../modules/tensor.py:315\u001b[0m, in \u001b[0;36mTensor.__init__\u001b[0;34m(self, data, dtype, requires_grad, is_leaf)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__dtype \u001b[38;5;241m=\u001b[39m dtype \u001b[38;5;66;03m#important to declare it before data because we'll use to convert the data type\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data\u001b[49m \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__requires_grad \u001b[38;5;241m=\u001b[39m requires_grad\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_leaf \u001b[38;5;241m=\u001b[39m is_leaf\n",
      "File \u001b[0;32m/mnt/g/my_stuff/masters/saclay/courses/M1/Object-Orietnted Programming/project/tests/notebooks/../modules/tensor.py:486\u001b[0m, in \u001b[0;36mTensor.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    484\u001b[0m dimensions\u001b[38;5;241m=\u001b[39mTensor\u001b[38;5;241m.\u001b[39mvalidate_tensor_input(value)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# super().__setattr__( name, Tensor.cast_dtype(value))\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[name] \u001b[38;5;241m=\u001b[39m \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Tensor__shape\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dimensions\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Tensor__ndim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dimensions) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dimensions)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlist\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/mnt/g/my_stuff/masters/saclay/courses/M1/Object-Orietnted Programming/project/tests/notebooks/../modules/tensor.py:467\u001b[0m, in \u001b[0;36mTensor.cast_dtype\u001b[0;34m(l, dt)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [Tensor\u001b[38;5;241m.\u001b[39mcast_dtype(sublist, dt) \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m l]\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdt\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/g/my_stuff/masters/saclay/courses/M1/Object-Orietnted Programming/project/tests/notebooks/../modules/tensor.py:304\u001b[0m, in \u001b[0;36mdtype.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(x)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m==\u001b[39m dtype\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'tuple'"
     ]
    }
   ],
   "source": [
    "# successful: pytorch behavior\n",
    "\n",
    "for i in bad_lists:\n",
    "    print(f'')\n",
    "    t=tensor(i)\n",
    "    print(f'bad list: {t}\\n\\tndim:{t.ndim}; shape:{t.shape}; no size function created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1=tensor([1,2,3])\n",
    "len(vec1) #3\n",
    "\n",
    "scalar1=tensor(1)\n",
    "# len(scalar1) #error, expected 0D tensor - even in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([1.0, 2.0, 3.0], dtype=float64, requires_grad=False, is_leaf=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elemtwise multiplication\n",
    "vec1*scalar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[9, 12, 15], [19, 26, 33], [29, 40, 51]], dtype=int64, requires_grad=False, is_leaf=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1=tensor([[1,2],[3,4],[5,6]],dtype='int64')\n",
    "matrix2=tensor([[1,2,3],[4,5,6]],dtype='int64')\n",
    "\n",
    "matrix1@matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[9.0, 12.0, 15.0], [19.0, 26.0, 33.0], [29.0, 40.0, 51.0]], dtype=float64, requires_grad=False, is_leaf=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1=tensor([[1,2],[3,4],[5,6]],dtype='int64')\n",
    "matrix2=tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "matrix1@matrix2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
