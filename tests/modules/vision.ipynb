{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MNIST, viz_ndarray\n",
    "from dataloader import DataLoader\n",
    "from transforms import *\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MNIST/raw/train-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/train-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/train-labels-idx1-ubyte already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte.gz already exists\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte already exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- these are examples of training 5 data points (shape of tensor and label):\n",
      "(1, 28, 28) 5\n",
      "(1, 28, 28) 0\n",
      "(1, 28, 28) 4\n",
      "(1, 28, 28) 1\n",
      "(1, 28, 28) 9\n",
      "x type: <class 'tensor.Tensor'>, y type: <class 'int'>\n",
      "x shape: (1, 28, 28), y shape: no shape its an int\n"
     ]
    }
   ],
   "source": [
    "train_data=MNIST(root='data', train=True, download=True)\n",
    "\n",
    "viz_ndarray(train_data[0][0],label=f'label: {train_data[0][1]}', squeeze=True)\n",
    "print('-- these are examples of training 5 data points (shape of tensor and label):')\n",
    "for i in range(5):\n",
    "    print(train_data[i][0].shape, train_data[i][1])\n",
    "\n",
    "for x,y in train_data:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- these are examples of training 5 data points (shape of tensor and label):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-- these are examples of training 5 data points (shape of tensor and label):\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch_train_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, torch_train_data[i][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m torch_train_data:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "torch_train_data = datasets.MNIST('data', train=True, download=True)\n",
    "print('-- these are examples of training 5 data points (shape of tensor and label):')\n",
    "for i in range(5):\n",
    "    print(torch_train_data[i][0].shape, torch_train_data[i][1])\n",
    "for x,y in torch_train_data:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: no shape its an int')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: min: 0, max: 255\n",
      " :O already a tensor\n",
      "after transform: min: 0.0, max: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_data=MNIST(root='data', train=True, download=True)\n",
    "\n",
    "x=train_data[0][0]\n",
    "print(f'before transform: min: {np.min(x.data)}, max: {np.max(x.data)}')\n",
    "ToTensor()(x) #performs transformation inplace, now x is modified\n",
    "print(f'after transform: min: {np.min(x.data)}, max: {np.max(x.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now putting it into use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=MNIST(root='data', train=True, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_loader:\n",
    "    print(f'x type: {type(x)}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_train_loader=torch.utils.data.DataLoader(torch_train_data, batch_size=32)\n",
    "\n",
    "for x,y in torch_train_loader:\n",
    "    print(f'x type: {type(x)} and dtype: {x.dtype}, y type: {type(y)}')\n",
    "    print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "    print('data:', x)\n",
    "    print('label:', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(x, y) in enumerate(train_loader):\n",
    "    print(f'batch number: {i} | x shape: {x.shape}  |  y: {y}, type y: {type(y)}')\n",
    "    if i==5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
